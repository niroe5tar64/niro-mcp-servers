# 壁打ちメモ

## 目的

MFR論文とcc-sddの関係性を手がかりに、「明示化ファースト」というテーマを自分の言葉で理解し、次の行動に落とす。

## いまの理解（要点）

- LLMの失敗は「推論力不足」より「問題表現が暗黙で不安定」なことが原因。
- MFRは推論の前に、エンティティ/状態/行動/制約を明示化させる。
- cc-sddも、実装前に仕様を明示化して解釈の揺れを減らす。
- 両者は「先に構造を作るほど、後の推論/実装が安定する」という同一原理に乗っている。
- 関係性の理解: MFRは理論的原理、cc-sddはその実用的な運用例として捉えられる。

## 用語の整理

- 問題モデル: 対象世界の構造（エンティティ、状態変数、行動、制約）を明示したもの。
- 明示化ファースト: 推論や実装の前に、構造や前提を先に外化するやり方。
- 表現の失敗: 不完全なモデルに基づいた推論で、結果が崩れること。
- CoT（Chain-of-Thought）: 解答の前に段階的な推論手順を書かせるプロンプト手法。推論の「やり方」を改善するが、問題構造の明示化は要求しない。
- ReAct（Reasoning + Acting）: 推論と行動（ツール実行や観測）を交互に行うエージェント手法。状態は自然言語で暗黙追跡されやすい。
- エンティティ: 問題空間に登場する主体や対象（人、物、システム、リソースなど）。
- 状態変数: エンティティの性質や条件で、時間とともに変化しうる属性（例: 在庫数、位置、ステータス）。
- 行動: 状態を変化させる操作やイベント。前提条件（実行条件）と効果（状態の変化）を伴う。
- 制約: 常に満たすべきルールや不変条件（例: 容量上限、同時実行不可、順序条件）。

## 具体例で考える（自分の案件で）

- 対象タスク:
- エンティティ:
- 状態変数:
- 行動（前提/効果）:
- 制約:
- 暗黙だった前提は何だったか:

## cc-sddへの当てはめ

- requirementsで問題モデルの骨格を明示できているか:
- designでモデルの整合性が固定されているか:
- tasks/implでモデル逸脱の検出ポイントはあるか:

## MFRの実践例として主張できるようにする変更案

- requirementsテンプレに「問題モデル」セクションを追加し、エンティティ/状態変数/行動(前提・効果)/制約を必須化する。
- designテンプレに「モデル確定」セクションを追加し、要件モデルの確定版と設計要素への対応付け（データモデル・制約の適用箇所）を明記する。
- tasksテンプレに「モデル参照」欄を追加し、各タスクがどのモデル要素に基づくかを明示する。
- validate-design/validate-implのレビュー項目に「モデル定義の有無/一貫性/制約の実装反映」を追加する。
- 運用ルールとして、モデル更新時は要件・設計の両方を更新し、モデルを単一の真実とする。
- 可能なら「problem-model.md」を新設し、requirements/designから参照する形にする（重複防止とモデル固定のため）。

## これらの変更で期待できる改善

- 仕様の暗黙前提が減り、要件の抜け漏れ・制約違反が早期に露出する。
- 要件→設計→タスク→実装の一貫性が高まり、後戻りや再解釈のコストが下がる。
- レビュー時に「モデルとの差分」で不整合を検出でき、確認負荷が下がる。
- タスクがモデルに紐づくため、実装が仕様から逸脱しにくい。
- 長期・複雑な機能でも状態整合性を保ちやすく、テスト観点の網羅性が上がる。

## 変更案の具体化

- requirementsテンプレの具体案は `explicit-modeling-discussion/improvement/01_requirements-template-mfr.md` に分離した。
- designテンプレの具体案は `explicit-modeling-discussion/improvement/02_design-template-mfr.md` に分離した。
- tasksテンプレの具体案は `explicit-modeling-discussion/improvement/03_tasks-template-mfr.md` に分離した。
- validate-design/validate-impl の具体案は `explicit-modeling-discussion/improvement/04_validate-review-mfr.md` に分離した。
- 運用ルール（モデル更新時の同期）の具体案は `explicit-modeling-discussion/improvement/05_operations-rule-mfr.md` に分離した。
- problem-model.md 新設の具体案は `explicit-modeling-discussion/improvement/06_problem-model-md-mfr.md` に分離した。

## 導入順の提案（優先順位）

### フェーズ1: 最小のモデル明示化

- 01_requirements-template-mfr: 要件段階でモデルを明示化し、抜け漏れを減らす。
- 02_design-template-mfr: モデル確定と制約担保を設計に接続する。

### フェーズ2: 実装の追跡と検証

- 03_tasks-template-mfr: タスクにモデル参照を付け、逸脱を検出しやすくする。
- 04_validate-review-mfr: 設計/実装レビューにモデル整合の検査を組み込む。

### フェーズ3: 運用の一貫性と単一の真実

- 05_operations-rule-mfr: 変更時の同期ルールを確立する。
- 06_problem-model-md-mfr: 必要に応じて単一の問題モデルを新設し、重複を解消する。

### 進め方の目安

- まずはフェーズ1のみを小さな機能で試す。
- 次にフェーズ2でタスクと検証の粒度を上げる。
- 最後にフェーズ3で運用を固定し、規模拡大に対応する。

## MFRで顕在化するコスト/リスク（従来から存在）

- モデル構築のコストは従来から存在し、暗黙化や属人的対応で見えにくかっただけかもしれない。
- モデル構築の誤りは従来も致命傷になり得たが、優秀な人材の機転で回避できていた可能性がある。
- MFRはこれらを前倒しで可視化するため、弱点というより運用上の注意点として扱う。
- 形式化しすぎて柔軟性を失うリスクは残るため、粒度の調整が重要。

## 次に深掘りしたい問い

- 明示化の「最低限ライン」はどこか（どの粒度で十分か）
- モデルの正しさをどう検証するか（人手レビュー? テスト?）
- cc-sddのテンプレに組み込むなら、どこにどう置くのが自然か

## 明示化の最低限ライン（暫定）

目的: 実装や推論の失敗を防ぐのに必要十分なモデルを、最小コストで確保する。

### 最低限の要素

- エンティティ: 行動の対象になるもの、または制約を受けるものを列挙する。
- 状態変数: 受け入れ基準や制約の判定に必要な属性だけを書く。
- 行動: 状態を変える操作のみ。各行動に「前提/効果」を最小限で付ける。
- 制約: 常に満たすべき不変条件と、順序や容量のルールだけを書く。

### 十分性の判定基準

- 受け入れ基準を、モデルの要素だけで検証できる。
- どの行動も、前提と効果がないと制約検証ができない箇所が残っていない。
- すべての制約が、明示された状態変数とエンティティにのみ依存している。
- 追加情報がなくても、正しい/誤りの判定ができる。

### 粒度を抑えるルール

- 具体的な値よりも「カテゴリ」や「範囲」で表現できるならそうする。
- 新しい詳細を追加しても、制約や行動の結果が変わらないなら追加しない。
- 例外系は、制約に影響するものだけを先に入れる（細部は後回し）。

### まず書くべき順序

1) 制約（やってはいけないこと）を列挙する。
2) 制約に必要な状態変数を定義する。
3) 主要行動の前提/効果を定義する。
4) エンティティの抜けを補う。

### 失敗が起きやすい兆候

- 「暗黙の前提があるはず」と感じるが、どこにも書かれていない。
- 受け入れ基準の文章が、モデルの要素に分解できない。
- タスクがモデルに紐づかず、説明が行き来している。

### 雑感

- 最低限ラインは実践しながら事例を増やし、試行錯誤で見極める必要がある。
- 当面は運用しつつ、後で基準を再評価する。

## モデルの正しさをどう検証するか（暫定）

前提: 実践で知見を蓄えることが不可欠。初期は軽量な検証から始める。

### 人手レビュー

- 要件/受け入れ基準とのトレーサビリティを確認する（基準がモデルに落ちているか）。
- 制約と状態変数の依存関係に矛盾がないかを確認する。
- 代表的なシナリオで、モデルだけで正誤判定できるかを机上検証する。

### テスト/自動検証

- 状態遷移テスト: 行動の前提/効果が矛盾しないかを確認する。
- モデルベーステスト: モデルから期待ケースを生成し、実装結果と照合する。
- 性質ベーステスト: 制約が常に満たされることをプロパティとして検証する。

### モデルベーステストの最小セット例

例: 予約/在庫のモデル（在庫数、予約作成/取消、在庫上限の制約）

- 代表ケース1: 在庫1のとき予約作成 → 在庫0になり、予約件数が1増える。
- 代表ケース2: 在庫0のとき予約作成 → 失敗し、在庫と予約件数は不変。
- 代表ケース3: 予約取消 → 在庫が1増え、予約件数が1減る。
- 代表ケース4: 連続操作（作成→取消）で初期状態に戻る。

### 状態遷移テストの具体例

例: タスクの状態遷移（Draft → Ready → InProgress → Done）

- 正常遷移: Draft から Ready へ遷移できる。
- 異常遷移: Draft から Done へは遷移できない（前提違反）。
- 効果確認: InProgress から Done へ遷移すると、完了日時が設定される。
- 不変条件: Done になったタスクは再度 InProgress に戻せない。

### 運用ルール

- モデル変更時は要件/設計/タスクに反映し、差分をレビューする。
- 仕様レビューで「モデルの抜け/矛盾/過剰」をチェックする。

## レビュー手順/運用ルールを具体化する観点

### モデル品質の観点

- 完全性: 受け入れ基準がモデル要素に分解できるか。
- 一貫性: 制約と状態変数の依存関係に矛盾がないか。
- 最小性: なくても制約検証に影響しない要素が混入していないか。

### トレーサビリティの観点

- 要件→モデル→設計→タスクの参照が切れていないか。
- 重要制約がどの設計/テストで担保されるか明記されているか。

### 実装整合性の観点

- 行動の前提/効果が実装のAPI/状態遷移に反映されているか。
- 状態遷移の禁止パスが、実装で実際に拒否されるか。

### 変更管理の観点

- モデル差分が出たときに要件/設計/タスクが同期更新されるか。
- モデル変更がレビューゲートを通る運用になっているか。

### 例外/リスクの観点

- 例外処理が制約を破らないか（例外で状態が破綻しないか）。
- 運用で「暗黙の前提」が増えていないかを定期的に点検する。

## レビュー品質のスキル依存について

- 意義はある。レビュー品質が個人スキルに依存する事実を認識することで、ばらつきを減らす施策を設計できる。
- 具体策: チェックリスト化、例題による校正、ペアレビュー、レビュー観点のテンプレ化、合格基準の明文化。
- 目的: 個人の能力に頼り切らず、再現性のあるレビューを目指す。
- 運用メモ: ここも実運用で知見を蓄え、定期的に基準をブラッシュアップする。

---

## 第三者レビュー（2025-12-27）

本節は、ここまでの議論内容に対する第三者目線での評価を記録したものである。

### 思考の根拠と論理の流れ

1. **根拠**: MFR論文 (arXiv:2512.14474v1, 2025)
   - LLMの失敗は「推論能力不足」ではなく「問題表現が暗黙で不安定」なことに起因
   - 推論前にエンティティ/状態変数/行動/制約を明示化すると、制約違反と不整合が減る

2. **アナロジーの構築**
   - MFR: 推論プロセス内で「問題モデル」を先に作る
   - cc-sdd: 開発プロセスで「仕様」を先に作る
   - → 両者は「先に構造を作るほど、後の推論/実装が安定する」という共通原理

3. **提案**: cc-sddにMFRの概念を組み込む
   - requirements/design/tasks/validateの各テンプレートに「問題モデル」の明示化を追加
   - 段階的導入（フェーズ1→2→3）でリスクを抑える

### 妥当と判断できる点

| 観点 | 評価 |
|------|------|
| 論文の理解 | 正確。MFRの主張「表現の失敗」を的確に捉えている |
| アナロジーの構築 | 論理的に筋が通る。「明示化→推論」の構造は類似 |
| 段階的導入 | 実践的。「小さな機能で試す」姿勢は適切 |
| リスク認識 | 「モデル構築コスト」「形式化しすぎるリスク」を自覚している |
| 最低限ラインの設定 | 「受け入れ基準をモデル要素で検証できる」は実用的な基準 |

### 懸念点・批判的考察

**1. 論文自体の限界がそのまま残る**

MFR論文は「選定例に基づく定性評価」であり、制約駆動の計画問題に限定されている。論文自身が「網羅的ベンチマークではない」と認めている。

→ cc-sddへの適用可能性は「仮説」であり、効果の保証はない。

**2. アナロジーの射程に限界がある**

| MFR | cc-sdd |
|-----|--------|
| LLMへのプロンプト設計 | 人間とAIの協働プロセス設計 |
| 推論の「直前」に明示化 | フェーズ間で明示化 |
| 対象: 単一のLLMセッション | 対象: 開発ライフサイクル全体 |

MFRが効果を発揮するのは「LLMの暗黙状態追跡」を外化するから。人間の開発プロセスにそのまま適用できるかは別問題。

**3. コスト-効果のトレードオフが未定量**

- 「モデル明示化のコスト」の具体的な見積もりがない
- どの規模・種類のプロジェクトで効果が高いかの判断基準がない
- 論文でも「トークンコスト増」を指摘しているが、増加率は不明

**4. 問題モデルの「正しさ」検証が最大のリスク**

論文も「モデル構築の精度が品質を左右する」と認めている。問題モデル自体が誤っていれば、すべての後続が破綻する。

discussion-notes.mdでは「人手レビュー」「モデルベーステスト」を挙げているが、これらはモデル明示化と同等以上のコストがかかる可能性がある。

**5. 適用領域の限定が必要**

論文も「構造化された制約駆動タスクで効果が顕著」と限定している。

- 探索的開発、創造的プロトタイピング、要件不明確なフェーズには過剰
- すべての問題が「エンティティ/状態/行動/制約」で表現できるわけではない

### 総合判断

**論理的には妥当だが、実証が不足している**

| 項目 | 評価 |
|------|------|
| 論文解釈の正確さ | ◎ |
| アナロジーの論理構造 | ○ |
| 実践的な導入設計 | ○ |
| 実証・定量化 | △ |
| 適用範囲の限定 | △ |

現時点では「試す価値のある仮説」であり、「確立された手法」ではない。「実践しながら事例を増やし、試行錯誤で見極める」という本文中の認識と整合している。

### 次のステップとして望ましいこと

1. **小規模な機能で試験導入** → 効果とコストを定量的に計測
2. **LLMエージェントの挙動確認** → 問題モデルセクションをどう活用するか
3. **問題モデルの品質担保** → 誤ったモデルを検出する仕組みを先に設計
