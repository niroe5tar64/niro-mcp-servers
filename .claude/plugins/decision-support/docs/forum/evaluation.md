# Multi-Agent 議論の効果と課題

本ドキュメントは、複数AI Agent会議の効果・課題・価値について整理したものである。

## 期待できる効果

### 1. 視点の網羅性向上

| 単純な壁打ち | 複数Agent会議 |
|-------------|--------------|
| 聞かれたことに答える | ロールが観点を強制的に分離 |
| 抜け漏れは質問者依存 | `risk-security`が見落としを拾う構造 |

例: 「この機能どう思う？」と聞くと良い点を中心に答えがちだが、`ops-cost`ロールがいれば運用負荷の懸念が出やすい。

### 2. 思考の深掘り促進

- 異なるロール間の「摩擦」が論点を浮き彫りにする
- `architect`の「拡張性重視」vs `ops-cost`の「シンプルさ重視」など
- 単純な壁打ちでは「どちらも大事」で終わりがち

### 3. 議論の構造化・再現性

- ワークフローが決まっているため、毎回同じ品質の検討ができる
- ログが残り、後から「なぜこの決定をしたか」を追跡可能
- 属人化しにくい

### 4. 認知負荷の分散

- 人間が全ての観点を同時に考える必要がない
- 「セキュリティはAIに任せて、自分はUXに集中」が可能

## 改善が難しい課題

### 1. 「同じ脳」問題

全ロールが同一のLLMから生成されるため、根本的なバイアスや知識の欠落は共有される。人間の多様なチームのような「本当の視点の違い」は生まれない。

例: 全員が同じ技術スタックしか知らない状態と同じ。

### 2. 表面的な対立になりやすい

- ロールを演じているだけで、本気で反論するインセンティブがない
- 「それも一理ありますね」で収束しがち
- 真剣な議論の緊張感が欠ける

### 3. コンテキスト希薄化

| 単純な壁打ち | 複数Agent会議 |
|-------------|--------------|
| 文脈が蓄積 | ロール切り替えで文脈が薄れる |
| 深い議論が可能 | 表層的な意見交換になりやすい |

### 4. オーバーヘッド

- 単純な問いに対しても「会議」を回すコスト
- 明らかな答えがある場合でも全ロールから意見を集める無駄
- 適切な使い分けの判断が難しい

### 5. 収束の難しさ

- facilitatorも同じLLMなので「どの意見を重視すべきか」の判断基準が曖昧
- 結局、人間が判断する必要がある部分は変わらない

## 人間の介入による緩和

上記の課題は「AIだけで自動的に回した場合」を想定している。人間がファシリテーターとして議論に介入することで、いくつかの課題は緩和できる。

### 緩和可能性の一覧

| 課題 | 人間の介入による緩和 | 緩和度 |
|------|---------------------|--------|
| 「同じ脳」問題 | 外部知識・経験を注入、「この観点はどう？」と誘導 | 中〜高 |
| 表面的な対立 | 「もっと強く反論して」「デメリットを3つ挙げて」と促す | 高 |
| コンテキスト希薄化 | 重要な文脈を繰り返し注入、要約を補強 | 中 |
| オーバーヘッド | 適切な場面を選んで使う判断 | 高 |
| 収束の難しさ | 人間が最終判断を下す | 完全解決 |

### 介入の具体例

**「同じ脳」問題の緩和：**

```
人間: 「architectは拡張性を重視しているが、
       うちのチームは3人しかいない。
       その制約を踏まえてops-costはどう思う？」
```

AIが知らない現実の制約を注入することで、視点の違いを生み出せる。

**表面的な対立の緩和：**

```
人間: 「risk-securityは『問題ない』と言ったが、
       もし攻撃者の視点で考えたら本当に穴はないか？
       最悪のシナリオを3つ考えて」
```

明示的に反論を要求することで、同調傾向を打破できる。

### 人間の介入でも残る課題

- **人間の認知負荷増加** - 介入が多いと「単純な壁打ちの方が楽」になる
- **人間のバイアス** - 人間自身が持つ盲点は補正されない
- **スキル依存** - 良いファシリテーションができるかは人次第

## 効果が期待できるケース

| 効果あり | 効果薄い |
|---------|---------|
| 複雑な意思決定（アーキテクチャ選定） | 単純な実装方法の質問 |
| トレードオフの明確化 | 正解が1つの問題 |
| 抜け漏れチェック（レビュー的用途） | 探索的なブレスト |
| ドキュメント化が必要な決定 | カジュアルな相談 |

## それでも価値がある条件

### 1. 「チェックリストの代替」として使う場合

目的を「創造的な議論」ではなく「観点の網羅確認」に絞る。

- 人間が考えた案を、複数ロールに「レビュー」させる
- 「同じ脳」でも、強制的に異なる切り口で見るプロンプトには意味がある
- OWASP Top 10のように「チェック項目を擬人化した」と考える

### 2. 思考の外部化・記録が必要な場合

- 意思決定の根拠を後から説明する必要がある組織
- 「なぜこの選択をしたか」をログとして残したい
- 単純な壁打ちより構造化された記録が残る

### 3. 人間の認知バイアスを補正したい場合

人間が「この設計良さそう！」と思った時：
- 単純な壁打ち: 「いいですね」と同調しがち
- 複数Agent会議: `risk-security`が強制的に懸念を出す

ロールがあることで「反論する役割」が明示され、同調圧力を軽減できる。

## 結論

「複数Agent会議」は、人間のチームミーティングの代替ではなく、**構造化されたセルフレビュー手法**として位置づけるのが適切である。

この位置づけであれば価値がある。「会議」より「多角的レビュープロセス」と呼んだ方が期待値が合うかもしれない。

### 推奨アプローチ

1. 最初から完璧を期待しない
2. 効果があったケース／なかったケースを記録する
3. 「壁打ちで十分だった」と判断したら戻せばいい

実験として回してみて、実際の意思決定に役立つかを検証することを推奨する。
